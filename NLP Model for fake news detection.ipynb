{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bc6ebb",
   "metadata": {},
   "source": [
    "# NLP Model for fake news detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa45b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas library for importing the dataset into the Python environment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49921cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get the latest from TODAY Sign up for our news...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d  Conan On The Funeral Trump Will Be Invited...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s safe to say that Instagram Stories has fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Much like a certain Amazon goddess with a lass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At a time when the perfect outfit is just one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>The storybook romance of WWE stars John Cena a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>The actor told friends he’s responsible for en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>Sarah Hyland is getting real.  The Modern Fami...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>Production has been suspended on the sixth and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>A jury ruled against Bill Cosby in his sexual ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Get the latest from TODAY Sign up for our news...      1\n",
       "1     2d  Conan On The Funeral Trump Will Be Invited...      1\n",
       "2     It’s safe to say that Instagram Stories has fa...      0\n",
       "3     Much like a certain Amazon goddess with a lass...      0\n",
       "4     At a time when the perfect outfit is just one ...      0\n",
       "...                                                 ...    ...\n",
       "4981  The storybook romance of WWE stars John Cena a...      0\n",
       "4982  The actor told friends he’s responsible for en...      0\n",
       "4983  Sarah Hyland is getting real.  The Modern Fami...      0\n",
       "4984  Production has been suspended on the sixth and...      0\n",
       "4985  A jury ruled against Bill Cosby in his sexual ...      0\n",
       "\n",
       "[4986 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'D:\\Data science and AI\\NLP\\fakenews.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ec2cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4986, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are two columns one with text and another with label 0 or 1 i.e, real or fake\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177d8849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2972\n",
       "1    2014\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d61b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2972 real and 2014 fake news out of the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2445104c",
   "metadata": {},
   "source": [
    "### {0 : 'real', 1 : 'fake'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23615aaa",
   "metadata": {},
   "source": [
    "### Let's build an NLP model for doing fake news classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e02f2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff7f8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get the latest from TODAY Sign up for our news...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d  Conan On The Funeral Trump Will Be Invited...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s safe to say that Instagram Stories has fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Much like a certain Amazon goddess with a lass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At a time when the perfect outfit is just one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Get the latest from TODAY Sign up for our news...      1\n",
       "1  2d  Conan On The Funeral Trump Will Be Invited...      1\n",
       "2  It’s safe to say that Instagram Stories has fa...      0\n",
       "3  Much like a certain Amazon goddess with a lass...      0\n",
       "4  At a time when the perfect outfit is just one ...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # To know about the datatset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840f1bc",
   "metadata": {},
   "source": [
    "#### Data pre-processing steps for building an NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0440fe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\weclome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3323377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\weclome\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d58b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing is essential to build an efficient corpus without special characters and irregular spaces\n",
    "\n",
    "corpus = [] # Define a corpus to build our dataframe for analysis and model building \n",
    "\n",
    "for i in range(0,4986):\n",
    "    \n",
    "    # To remove special characters\n",
    "    document = re.sub(r'\\W',' ',data['text'][i])\n",
    "    \n",
    "    # To remove single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+',' ',document)\n",
    "    \n",
    "    # To remove single characters from starting\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+',' ',document)\n",
    "    \n",
    "    # To remove more spacs and replace with single space\n",
    "    document = re.sub(r'\\s+',' ',document,flags=re.I)\n",
    "    \n",
    "    document = document.lower()\n",
    "    \n",
    "    document = document.split()\n",
    "    \n",
    "    document = [stemmer.lemmatize(w) for w in document]\n",
    "    \n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    corpus.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23fc877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the latest from today sign up for our newsletter no one ever truly get over losing loved one and blake shelton is no exception he wa just 14 when his older brother richie died on nov 13 1990 and a shelton noted in tweet monday it changed my life forever richie wa 24 when he died in car accident in the sheltons home state of oklahoma two year ago shelton sent out message for the 25th anniversary of his loss richie who wa blake half brother they shared mother wa passenger in car that collided with school bus in ada south of oklahoma city richie driver redena mcmanus and 3 year old boy christopher mcmanus all died during or shortly after the collision while the bus driver and passenger were uninjured according to police report the accident ha clearly remained with blake who told 60 minute in 2014 remember picking up the phone to call him week after he wa dead to tell him something wa picking up the phone to call him to tell him something just saw on tv or and it wa like constantly shock to me that he wa dead blake shelton playing at today halloween extravaganza in new york city on oct 31 getty image in 2011 blake and his then wife miranda lambert wrote single called over you which wa inspired by richie still the two brother had bonded despite the age difference both shared love of country music his bedroom wa right across the hallway from mine when wa little blake said in that interview and he wa listening to hank williams jr or waylon lynyrd skynyrd or bob seeger just whatever wa popular really richie loved all music and would be sitting there going man that guy my hero that the coolest guy he my big brother follow randee dawn on twitter\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44802d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divding data into features and target variables where X is corpus and y is target (fake or real)\n",
    "X = corpus\n",
    "y = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ae7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data into train and test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8153abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e930d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626d41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using countvectorizer for the corpus dataframing\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words = stopwords.words('english'))\n",
    "\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5802cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '08', '10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1997', '1998', '1999', '20', '200', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '48', '49', '50', '53', '54', '60', '65', '70', '80', '90', 'abc', 'ability', 'able', 'absolutely', 'abuse', 'academy', 'according', 'account', 'accused', 'across', 'act', 'acting', 'action', 'actor', 'actress', 'actually', 'adam', 'add', 'added', 'adding', 'addition', 'address', 'admitted', 'advertisement', 'affair', 'affleck', 'afp', 'age', 'agent', 'ago', 'agree', 'agreed', 'agreement', 'aguilera', 'ahead', 'air', 'aired', 'al', 'album', 'allegation', 'alleged', 'allegedly', 'allowed', 'almost', 'alone', 'along', 'alongside', 'already', 'also', 'although', 'always', 'amazing', 'america', 'american', 'among', 'amount', 'andrew', 'andy', 'angeles', 'angelina', 'animal', 'aniston', 'announced', 'announcement', 'annual', 'another', 'answer', 'anthony', 'anymore', 'anyone', 'anything', 'ap', 'apart', 'apartment', 'apparently', 'appear', 'appearance', 'appeared', 'appears', 'applause', 'april', 'area', 'arm', 'around', 'arrived', 'art', 'article', 'artist', 'ask', 'asked', 'asking', 'assault', 'attack', 'attempt', 'attend', 'attended', 'attends', 'attention', 'attorney', 'audience', 'august', 'australia', 'available', 'avenger', 'award', 'away', 'baby', 'bachelor', 'back', 'bad', 'ball', 'band', 'bank', 'barack', 'based', 'battle', 'bbc', 'beach', 'beautiful', 'beauty', 'became', 'beckham', 'become', 'becoming', 'began', 'begin', 'beginning', 'behavior', 'behind', 'belief', 'believe', 'believed', 'ben', 'benefit', 'best', 'better', 'beverly', 'beyoncé', 'beyond', 'bieber', 'big', 'biggest', 'bill', 'billboard', 'billion', 'billy', 'birth', 'birthday', 'bit', 'black', 'blake', 'blood', 'blue', 'board', 'bob', 'body', 'book', 'border', 'born', 'bowl', 'box', 'boy', 'boyfriend', 'brad', 'brand', 'break', 'breaking', 'breakup', 'bring', 'british', 'broadcast', 'broke', 'broken', 'brother', 'brought', 'brown', 'bruce', 'building', 'bush', 'business', 'buy', 'caitlyn', 'california', 'call', 'called', 'calling', 'cambridge', 'came', 'camera', 'campaign', 'cancer', 'candidate', 'cannot', 'caption', 'captioned', 'car', 'card', 'cardi', 'care', 'career', 'carpet', 'case', 'cast', 'castle', 'category', 'caught', 'cause', 'caused', 'cbs', 'celebrate', 'celebrity', 'center', 'ceremony', 'certain', 'certainly', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charity', 'charles', 'chart', 'check', 'chicago', 'chief', 'child', 'choice', 'chris', 'christian', 'christmas', 'church', 'city', 'claim', 'claimed', 'claire', 'class', 'classic', 'clear', 'clearly', 'click', 'clinton', 'clip', 'clooney', 'close', 'club', 'cnn', 'co', 'coach', 'collection', 'college', 'color', 'com', 'come', 'comedy', 'comic', 'coming', 'comment', 'commercial', 'common', 'community', 'company', 'competition', 'complete', 'completely', 'concern', 'concert', 'condition', 'confirmed', 'congress', 'considered', 'content', 'contestant', 'continue', 'continued', 'continues', 'control', 'conversation', 'cool', 'cooper', 'cop', 'cornell', 'cost', 'could', 'country', 'county', 'couple', 'course', 'court', 'cover', 'coverage', 'crazy', 'create', 'created', 'credit', 'crew', 'crime', 'criminal', 'crisis', 'critic', 'critical', 'crowd', 'cruise', 'culture', 'cup', 'current', 'currently', 'custody', 'cut', 'cyrus', 'dad', 'daily', 'dance', 'dancing', 'dark', 'date', 'dating', 'daughter', 'david', 'day', 'de', 'dead', 'deal', 'death', 'debate', 'debut', 'decade', 'december', 'decided', 'decision', 'definitely', 'degeneres', 'delivered', 'denied', 'department', 'described', 'design', 'designer', 'despite', 'detail', 'development', 'diamond', 'diana', 'die', 'died', 'difference', 'different', 'difficult', 'dinner', 'directed', 'direction', 'director', 'disney', 'divorce', 'doctor', 'document', 'doe', 'dog', 'dollar', 'donald', 'done', 'door', 'double', 'doubt', 'dr', 'drake', 'drama', 'dream', 'dress', 'dropped', 'drug', 'duchess', 'due', 'duke', 'duo', 'earlier', 'early', 'earned', 'easy', 'economy', 'ed', 'edit', 'education', 'effect', 'effort', 'eight', 'either', 'election', 'elizabeth', 'ellen', 'else', 'email', 'emma', 'emmy', 'emotional', 'end', 'ended', 'energy', 'engaged', 'engagement', 'england', 'english', 'enough', 'entertainment', 'entire', 'episode', 'eric', 'especially', 'estate', 'et', 'even', 'evening', 'event', 'eventually', 'ever', 'every', 'everybody', 'everyone', 'everything', 'evidence', 'ex', 'exactly', 'example', 'excited', 'exclusive', 'exclusively', 'executive', 'expected', 'expecting', 'experience', 'explained', 'eye', 'face', 'facebook', 'fact', 'fair', 'fake', 'fall', 'fame', 'family', 'famous', 'fan', 'far', 'fashion', 'father', 'favorite', 'fear', 'feature', 'featured', 'featuring', 'february', 'federal', 'feel', 'feeling', 'fell', 'fellow', 'felt', 'female', 'festival', 'feud', 'field', 'fifth', 'fight', 'fighting', 'figure', 'filed', 'film', 'filming', 'final', 'finale', 'finally', 'financial', 'find', 'fine', 'fire', 'first', 'fisher', 'fit', 'five', 'focus', 'follow', 'followed', 'following', 'food', 'foot', 'force', 'forced', 'foreign', 'forever', 'form', 'former', 'forward', 'found', 'foundation', 'four', 'fourth', 'fox', 'free', 'french', 'friday', 'friend', 'friendship', 'front', 'full', 'fun', 'fund', 'funny', 'future', 'gala', 'game', 'garner', 'gave', 'gay', 'general', 'george', 'get', 'getting', 'getty', 'gift', 'girl', 'girlfriend', 'give', 'given', 'giving', 'global', 'globe', 'go', 'goal', 'god', 'going', 'gold', 'golden', 'gomez', 'gone', 'gonna', 'good', 'gossip', 'got', 'government', 'gown', 'grace', 'grammy', 'great', 'greatest', 'green', 'griffin', 'ground', 'group', 'growing', 'guardian', 'guest', 'gun', 'guy', 'gwen', 'ha', 'hair', 'half', 'hall', 'hand', 'hanging', 'happen', 'happened', 'happens', 'happy', 'harassment', 'hard', 'harry', 'harvey', 'hate', 'hbo', 'head', 'headline', 'health', 'healthy', 'hear', 'heard', 'heart', 'held', 'help', 'helped', 'henry', 'hero', 'high', 'highest', 'hill', 'hillary', 'history', 'hit', 'hold', 'holding', 'holiday', 'hollywood', 'holmes', 'home', 'honor', 'hope', 'hospital', 'host', 'hosted', 'hot', 'hotel', 'hour', 'house', 'housewife', 'however', 'http', 'huge', 'human', 'hurt', 'husband', 'idea', 'idol', 'ii', 'image', 'immediately', 'important', 'incident', 'include', 'included', 'includes', 'including', 'income', 'incredible', 'independent', 'individual', 'industry', 'influence', 'information', 'inside', 'insider', 'inspired', 'instagram', 'instead', 'insurance', 'interest', 'international', 'internet', 'interview', 'investigation', 'invited', 'involved', 'island', 'issue', 'jack', 'jackson', 'james', 'jamie', 'jane', 'january', 'jason', 'jay', 'jelena', 'jen', 'jenner', 'jennifer', 'jersey', 'jessica', 'jimmy', 'job', 'joe', 'john', 'johnson', 'join', 'joined', 'joke', 'jolie', 'jon', 'jones', 'jordan', 'journey', 'jr', 'judge', 'july', 'june', 'justice', 'justin', 'kanye', 'kardashian', 'kardashians', 'kate', 'katie', 'katy', 'keep', 'keeping', 'kelly', 'kendall', 'kensington', 'kept', 'kevin', 'key', 'khloe', 'khloé', 'kid', 'kill', 'killed', 'kim', 'kimmel', 'kind', 'king', 'kiss', 'knew', 'know', 'known', 'kourtney', 'kris', 'kylie', 'la', 'lady', 'lambert', 'large', 'last', 'late', 'later', 'latest', 'lauer', 'launched', 'lauren', 'law', 'lawrence', 'lawyer', 'le', 'lead', 'leader', 'leading', 'learn', 'learned', 'least', 'leave', 'leaving', 'led', 'lee', 'left', 'legal', 'legend', 'let', 'letter', 'level', 'liam', 'lie', 'life', 'light', 'like', 'likely', 'lindsay', 'line', 'link', 'lip', 'list', 'little', 'live', 'lived', 'living', 'local', 'lohan', 'london', 'long', 'longer', 'look', 'looked', 'looking', 'lopez', 'los', 'loss', 'lost', 'lot', 'love', 'loved', 'low', 'lyric', 'made', 'magazine', 'magic', 'mail', 'main', 'major', 'make', 'makeup', 'making', 'male', 'man', 'manager', 'manchester', 'many', 'march', 'mark', 'markle', 'marriage', 'married', 'martin', 'mary', 'match', 'matt', 'matter', 'may', 'maybe', 'mccain', 'mean', 'meant', 'meanwhile', 'medical', 'medium', 'meet', 'meeting', 'meghan', 'melania', 'member', 'memory', 'men', 'message', 'met', 'mexico', 'michael', 'michelle', 'middle', 'middleton', 'might', 'mike', 'miley', 'miller', 'million', 'mind', 'minute', 'miss', 'missing', 'mistake', 'model', 'mom', 'moment', 'monday', 'money', 'month', 'moore', 'morning', 'mother', 'move', 'moved', 'movie', 'moving', 'mr', 'mtv', 'much', 'multiple', 'murder', 'music', 'musical', 'musician', 'must', 'name', 'named', 'nation', 'national', 'nbc', 'near', 'nearly', 'need', 'needed', 'net', 'netflix', 'network', 'never', 'new', 'news', 'newsletter', 'next', 'nice', 'nick', 'nicole', 'night', 'nine', 'nominated', 'nomination', 'non', 'none', 'north', 'note', 'noted', 'nothing', 'notification', 'november', 'number', 'obama', 'obviously', 'october', 'offer', 'offered', 'office', 'officer', 'official', 'officially', 'often', 'oh', 'ok', 'old', 'older', 'olivia', 'olympic', 'one', 'online', 'open', 'opened', 'opening', 'opinion', 'opportunity', 'order', 'organization', 'original', 'originally', 'oscar', 'others', 'outlet', 'outside', 'page', 'paid', 'pain', 'pair', 'palace', 'parent', 'paris', 'park', 'part', 'particularly', 'partner', 'party', 'past', 'paul', 'pay', 'pdt', 'people', 'per', 'percent', 'perfect', 'perform', 'performance', 'performed', 'performing', 'perhaps', 'period', 'perry', 'person', 'personal', 'personality', 'peter', 'phone', 'photo', 'photographed', 'physical', 'pic', 'pick', 'picture', 'piece', 'pink', 'pitt', 'place', 'plan', 'play', 'played', 'player', 'playing', 'please', 'plus', 'point', 'police', 'policy', 'political', 'pop', 'popular', 'position', 'positive', 'possible', 'post', 'posted', 'power', 'powerful', 'pregnancy', 'pregnant', 'premiere', 'premiered', 'present', 'president', 'presidential', 'press', 'pretty', 'previous', 'previously', 'price', 'prince', 'princess', 'prior', 'prison', 'private', 'probably', 'problem', 'process', 'produced', 'producer', 'product', 'production', 'professional', 'profile', 'program', 'project', 'property', 'proud', 'provide', 'public', 'publication', 'publicly', 'published', 'push', 'put', 'putting', 'queen', 'question', 'quickly', 'quite', 'race', 'rachel', 'radio', 'raise', 'raised', 'rapper', 'rather', 'rating', 'reached', 'reaction', 'read', 'reading', 'ready', 'real', 'reality', 'really', 'reason', 'received', 'recent', 'recently', 'reception', 'record', 'recorded', 'recording', 'red', 'regina', 'regular', 'related', 'relationship', 'release', 'released', 'remember', 'rep', 'report', 'reported', 'reportedly', 'reporter', 'republican', 'request', 'respect', 'responded', 'response', 'rest', 'restaurant', 'result', 'return', 'returned', 'reunion', 'revealed', 'reveals', 'review', 'right', 'rihanna', 'ring', 'road', 'rob', 'robert', 'robin', 'rock', 'role', 'romance', 'romantic', 'room', 'rose', 'round', 'royal', 'rule', 'rumor', 'run', 'running', 'russian', 'ryan', 'safe', 'said', 'sale', 'sam', 'san', 'sander', 'sarah', 'saturday', 'save', 'saw', 'say', 'saying', 'scandal', 'scene', 'school', 'scott', 'screen', 'season', 'second', 'secret', 'secretary', 'security', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'selena', 'self', 'senator', 'sense', 'sent', 'separate', 'separation', 'september', 'sequel', 'series', 'serious', 'served', 'service', 'set', 'seven', 'several', 'sex', 'sexual', 'shape', 'share', 'shared', 'sharing', 'shelton', 'shirt', 'shocking', 'shoot', 'shooting', 'short', 'shortly', 'shot', 'show', 'showed', 'showing', 'side', 'sign', 'signed', 'similar', 'simply', 'since', 'singer', 'singing', 'single', 'sister', 'site', 'sitting', 'situation', 'six', 'skin', 'small', 'smith', 'social', 'sold', 'solo', 'somebody', 'someone', 'something', 'sometimes', 'son', 'song', 'soon', 'sorry', 'sort', 'sound', 'source', 'south', 'space', 'speak', 'speaking', 'special', 'speculation', 'speech', 'spend', 'spending', 'spent', 'split', 'spoke', 'sport', 'spot', 'spotted', 'springsteen', 'st', 'stage', 'stand', 'standing', 'star', 'starred', 'starring', 'start', 'started', 'starting', 'state', 'stated', 'statement', 'stay', 'stefani', 'step', 'stephen', 'steve', 'still', 'stone', 'stop', 'store', 'story', 'straight', 'stranger', 'street', 'strong', 'struggle', 'student', 'studio', 'stuff', 'stunt', 'style', 'subject', 'success', 'successful', 'suicide', 'suit', 'summer', 'sun', 'sunday', 'super', 'support', 'supporting', 'sure', 'surgery', 'surprise', 'sweet', 'swift', 'system', 'table', 'tabloid', 'take', 'taken', 'taking', 'talent', 'talk', 'talked', 'talking', 'tape', 'tax', 'taylor', 'team', 'teen', 'television', 'tell', 'telling', 'ten', 'term', 'texas', 'thank', 'thanks', 'theater', 'theroux', 'thing', 'think', 'thinking', 'third', 'thomas', 'thompson', 'though', 'thought', 'three', 'throne', 'throughout', 'thursday', 'time', 'title', 'titled', 'tmz', 'today', 'together', 'told', 'tom', 'tonight', 'tony', 'took', 'top', 'total', 'totally', 'touch', 'tough', 'tour', 'town', 'track', 'travel', 'treatment', 'trial', 'tried', 'trip', 'true', 'truly', 'trump', 'trust', 'truth', 'try', 'trying', 'tuesday', 'turn', 'turned', 'tv', 'tweet', 'tweeted', 'twin', 'twitter', 'two', 'type', 'uk', 'ultimately', 'understand', 'union', 'united', 'university', 'upcoming', 'upon', 'urban', 'usa', 'use', 'used', 'using', 'value', 'variety', 'various', 'vega', 'version', 'via', 'victim', 'victoria', 'video', 'view', 'viewer', 'visit', 'vocal', 'voice', 'vote', 'voted', 'wait', 'wake', 'walk', 'walked', 'walking', 'wall', 'want', 'wanted', 'war', 'washington', 'watch', 'watched', 'watching', 'water', 'way', 'wear', 'wearing', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weekly', 'weeknd', 'weight', 'weinstein', 'well', 'went', 'west', 'whatever', 'whether', 'white', 'whole', 'whose', 'wife', 'william', 'williams', 'win', 'windsor', 'winner', 'winning', 'winter', 'wish', 'witherspoon', 'within', 'without', 'woman', 'wonder', 'word', 'wore', 'work', 'worked', 'worker', 'working', 'world', 'worldwide', 'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writing', 'written', 'wrong', 'wrote', 'yard', 'yeah', 'year', 'yes', 'yet', 'york', 'young', 'younger', 'youtube']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e80fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yard</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3988 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  08  10  100  11  12  13  14  15  16  ...  wrote  yard  yeah  year  \\\n",
       "0       0   0   0    0   0   0   0   0   0   0  ...      1     0     0     2   \n",
       "1       0   0   2    0   1   0   0   0   0   0  ...      2     0     0     0   \n",
       "2       0   0   5    2   7  18   3  11  14   3  ...      1     1     0    41   \n",
       "3       0   0   0    0   0   0   0   0   0   0  ...      0     0     0     3   \n",
       "4       1   0   0    0   1   0   0   0   0   0  ...      0     0     0     2   \n",
       "...   ...  ..  ..  ...  ..  ..  ..  ..  ..  ..  ...    ...   ...   ...   ...   \n",
       "3983    0   0   0    0   0   0   0   0   1   0  ...      0     0     0     2   \n",
       "3984    0   0   0    0   0   0   0   0   0   0  ...      0     0     0     6   \n",
       "3985    0   0   1    0   0   0   0   0   0   0  ...      0     0     0     2   \n",
       "3986    0   0   0    0   0   0   0   0   0   0  ...      0     0     0     1   \n",
       "3987    0   0   0    0   0   0   0   0   0   0  ...      0     0     0     2   \n",
       "\n",
       "      yes  yet  york  young  younger  youtube  \n",
       "0       0    0     0      0        0        0  \n",
       "1       0    0     1      0        0        0  \n",
       "2       1    1     4      6        0        0  \n",
       "3       0    0     0      0        0        0  \n",
       "4       0    0     5      0        0        0  \n",
       "...   ...  ...   ...    ...      ...      ...  \n",
       "3983    0    0     0      0        0        0  \n",
       "3984    1    1     0      0        0        0  \n",
       "3985    0    0     0      1        0        0  \n",
       "3986    0    0     0      0        0        0  \n",
       "3987    0    0     1      1        0        1  \n",
       "\n",
       "[3988 rows x 1500 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_train.toarray(),columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "494ccd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidfvectorizer for the corpus dataframing\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49bb7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words = stopwords.words('english'))\n",
    "\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "943b5e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '08', '10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1997', '1998', '1999', '20', '200', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '48', '49', '50', '53', '54', '60', '65', '70', '80', '90', 'abc', 'ability', 'able', 'absolutely', 'abuse', 'academy', 'according', 'account', 'accused', 'across', 'act', 'acting', 'action', 'actor', 'actress', 'actually', 'adam', 'add', 'added', 'adding', 'addition', 'address', 'admitted', 'advertisement', 'affair', 'affleck', 'afp', 'age', 'agent', 'ago', 'agree', 'agreed', 'agreement', 'aguilera', 'ahead', 'air', 'aired', 'al', 'album', 'allegation', 'alleged', 'allegedly', 'allowed', 'almost', 'alone', 'along', 'alongside', 'already', 'also', 'although', 'always', 'amazing', 'america', 'american', 'among', 'amount', 'andrew', 'andy', 'angeles', 'angelina', 'animal', 'aniston', 'announced', 'announcement', 'annual', 'another', 'answer', 'anthony', 'anymore', 'anyone', 'anything', 'ap', 'apart', 'apartment', 'apparently', 'appear', 'appearance', 'appeared', 'appears', 'applause', 'april', 'area', 'arm', 'around', 'arrived', 'art', 'article', 'artist', 'ask', 'asked', 'asking', 'assault', 'attack', 'attempt', 'attend', 'attended', 'attends', 'attention', 'attorney', 'audience', 'august', 'australia', 'available', 'avenger', 'award', 'away', 'baby', 'bachelor', 'back', 'bad', 'ball', 'band', 'bank', 'barack', 'based', 'battle', 'bbc', 'beach', 'beautiful', 'beauty', 'became', 'beckham', 'become', 'becoming', 'began', 'begin', 'beginning', 'behavior', 'behind', 'belief', 'believe', 'believed', 'ben', 'benefit', 'best', 'better', 'beverly', 'beyoncé', 'beyond', 'bieber', 'big', 'biggest', 'bill', 'billboard', 'billion', 'billy', 'birth', 'birthday', 'bit', 'black', 'blake', 'blood', 'blue', 'board', 'bob', 'body', 'book', 'border', 'born', 'bowl', 'box', 'boy', 'boyfriend', 'brad', 'brand', 'break', 'breaking', 'breakup', 'bring', 'british', 'broadcast', 'broke', 'broken', 'brother', 'brought', 'brown', 'bruce', 'building', 'bush', 'business', 'buy', 'caitlyn', 'california', 'call', 'called', 'calling', 'cambridge', 'came', 'camera', 'campaign', 'cancer', 'candidate', 'cannot', 'caption', 'captioned', 'car', 'card', 'cardi', 'care', 'career', 'carpet', 'case', 'cast', 'castle', 'category', 'caught', 'cause', 'caused', 'cbs', 'celebrate', 'celebrity', 'center', 'ceremony', 'certain', 'certainly', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charity', 'charles', 'chart', 'check', 'chicago', 'chief', 'child', 'choice', 'chris', 'christian', 'christmas', 'church', 'city', 'claim', 'claimed', 'claire', 'class', 'classic', 'clear', 'clearly', 'click', 'clinton', 'clip', 'clooney', 'close', 'club', 'cnn', 'co', 'coach', 'collection', 'college', 'color', 'com', 'come', 'comedy', 'comic', 'coming', 'comment', 'commercial', 'common', 'community', 'company', 'competition', 'complete', 'completely', 'concern', 'concert', 'condition', 'confirmed', 'congress', 'considered', 'content', 'contestant', 'continue', 'continued', 'continues', 'control', 'conversation', 'cool', 'cooper', 'cop', 'cornell', 'cost', 'could', 'country', 'county', 'couple', 'course', 'court', 'cover', 'coverage', 'crazy', 'create', 'created', 'credit', 'crew', 'crime', 'criminal', 'crisis', 'critic', 'critical', 'crowd', 'cruise', 'culture', 'cup', 'current', 'currently', 'custody', 'cut', 'cyrus', 'dad', 'daily', 'dance', 'dancing', 'dark', 'date', 'dating', 'daughter', 'david', 'day', 'de', 'dead', 'deal', 'death', 'debate', 'debut', 'decade', 'december', 'decided', 'decision', 'definitely', 'degeneres', 'delivered', 'denied', 'department', 'described', 'design', 'designer', 'despite', 'detail', 'development', 'diamond', 'diana', 'die', 'died', 'difference', 'different', 'difficult', 'dinner', 'directed', 'direction', 'director', 'disney', 'divorce', 'doctor', 'document', 'doe', 'dog', 'dollar', 'donald', 'done', 'door', 'double', 'doubt', 'dr', 'drake', 'drama', 'dream', 'dress', 'dropped', 'drug', 'duchess', 'due', 'duke', 'duo', 'earlier', 'early', 'earned', 'easy', 'economy', 'ed', 'edit', 'education', 'effect', 'effort', 'eight', 'either', 'election', 'elizabeth', 'ellen', 'else', 'email', 'emma', 'emmy', 'emotional', 'end', 'ended', 'energy', 'engaged', 'engagement', 'england', 'english', 'enough', 'entertainment', 'entire', 'episode', 'eric', 'especially', 'estate', 'et', 'even', 'evening', 'event', 'eventually', 'ever', 'every', 'everybody', 'everyone', 'everything', 'evidence', 'ex', 'exactly', 'example', 'excited', 'exclusive', 'exclusively', 'executive', 'expected', 'expecting', 'experience', 'explained', 'eye', 'face', 'facebook', 'fact', 'fair', 'fake', 'fall', 'fame', 'family', 'famous', 'fan', 'far', 'fashion', 'father', 'favorite', 'fear', 'feature', 'featured', 'featuring', 'february', 'federal', 'feel', 'feeling', 'fell', 'fellow', 'felt', 'female', 'festival', 'feud', 'field', 'fifth', 'fight', 'fighting', 'figure', 'filed', 'film', 'filming', 'final', 'finale', 'finally', 'financial', 'find', 'fine', 'fire', 'first', 'fisher', 'fit', 'five', 'focus', 'follow', 'followed', 'following', 'food', 'foot', 'force', 'forced', 'foreign', 'forever', 'form', 'former', 'forward', 'found', 'foundation', 'four', 'fourth', 'fox', 'free', 'french', 'friday', 'friend', 'friendship', 'front', 'full', 'fun', 'fund', 'funny', 'future', 'gala', 'game', 'garner', 'gave', 'gay', 'general', 'george', 'get', 'getting', 'getty', 'gift', 'girl', 'girlfriend', 'give', 'given', 'giving', 'global', 'globe', 'go', 'goal', 'god', 'going', 'gold', 'golden', 'gomez', 'gone', 'gonna', 'good', 'gossip', 'got', 'government', 'gown', 'grace', 'grammy', 'great', 'greatest', 'green', 'griffin', 'ground', 'group', 'growing', 'guardian', 'guest', 'gun', 'guy', 'gwen', 'ha', 'hair', 'half', 'hall', 'hand', 'hanging', 'happen', 'happened', 'happens', 'happy', 'harassment', 'hard', 'harry', 'harvey', 'hate', 'hbo', 'head', 'headline', 'health', 'healthy', 'hear', 'heard', 'heart', 'held', 'help', 'helped', 'henry', 'hero', 'high', 'highest', 'hill', 'hillary', 'history', 'hit', 'hold', 'holding', 'holiday', 'hollywood', 'holmes', 'home', 'honor', 'hope', 'hospital', 'host', 'hosted', 'hot', 'hotel', 'hour', 'house', 'housewife', 'however', 'http', 'huge', 'human', 'hurt', 'husband', 'idea', 'idol', 'ii', 'image', 'immediately', 'important', 'incident', 'include', 'included', 'includes', 'including', 'income', 'incredible', 'independent', 'individual', 'industry', 'influence', 'information', 'inside', 'insider', 'inspired', 'instagram', 'instead', 'insurance', 'interest', 'international', 'internet', 'interview', 'investigation', 'invited', 'involved', 'island', 'issue', 'jack', 'jackson', 'james', 'jamie', 'jane', 'january', 'jason', 'jay', 'jelena', 'jen', 'jenner', 'jennifer', 'jersey', 'jessica', 'jimmy', 'job', 'joe', 'john', 'johnson', 'join', 'joined', 'joke', 'jolie', 'jon', 'jones', 'jordan', 'journey', 'jr', 'judge', 'july', 'june', 'justice', 'justin', 'kanye', 'kardashian', 'kardashians', 'kate', 'katie', 'katy', 'keep', 'keeping', 'kelly', 'kendall', 'kensington', 'kept', 'kevin', 'key', 'khloe', 'khloé', 'kid', 'kill', 'killed', 'kim', 'kimmel', 'kind', 'king', 'kiss', 'knew', 'know', 'known', 'kourtney', 'kris', 'kylie', 'la', 'lady', 'lambert', 'large', 'last', 'late', 'later', 'latest', 'lauer', 'launched', 'lauren', 'law', 'lawrence', 'lawyer', 'le', 'lead', 'leader', 'leading', 'learn', 'learned', 'least', 'leave', 'leaving', 'led', 'lee', 'left', 'legal', 'legend', 'let', 'letter', 'level', 'liam', 'lie', 'life', 'light', 'like', 'likely', 'lindsay', 'line', 'link', 'lip', 'list', 'little', 'live', 'lived', 'living', 'local', 'lohan', 'london', 'long', 'longer', 'look', 'looked', 'looking', 'lopez', 'los', 'loss', 'lost', 'lot', 'love', 'loved', 'low', 'lyric', 'made', 'magazine', 'magic', 'mail', 'main', 'major', 'make', 'makeup', 'making', 'male', 'man', 'manager', 'manchester', 'many', 'march', 'mark', 'markle', 'marriage', 'married', 'martin', 'mary', 'match', 'matt', 'matter', 'may', 'maybe', 'mccain', 'mean', 'meant', 'meanwhile', 'medical', 'medium', 'meet', 'meeting', 'meghan', 'melania', 'member', 'memory', 'men', 'message', 'met', 'mexico', 'michael', 'michelle', 'middle', 'middleton', 'might', 'mike', 'miley', 'miller', 'million', 'mind', 'minute', 'miss', 'missing', 'mistake', 'model', 'mom', 'moment', 'monday', 'money', 'month', 'moore', 'morning', 'mother', 'move', 'moved', 'movie', 'moving', 'mr', 'mtv', 'much', 'multiple', 'murder', 'music', 'musical', 'musician', 'must', 'name', 'named', 'nation', 'national', 'nbc', 'near', 'nearly', 'need', 'needed', 'net', 'netflix', 'network', 'never', 'new', 'news', 'newsletter', 'next', 'nice', 'nick', 'nicole', 'night', 'nine', 'nominated', 'nomination', 'non', 'none', 'north', 'note', 'noted', 'nothing', 'notification', 'november', 'number', 'obama', 'obviously', 'october', 'offer', 'offered', 'office', 'officer', 'official', 'officially', 'often', 'oh', 'ok', 'old', 'older', 'olivia', 'olympic', 'one', 'online', 'open', 'opened', 'opening', 'opinion', 'opportunity', 'order', 'organization', 'original', 'originally', 'oscar', 'others', 'outlet', 'outside', 'page', 'paid', 'pain', 'pair', 'palace', 'parent', 'paris', 'park', 'part', 'particularly', 'partner', 'party', 'past', 'paul', 'pay', 'pdt', 'people', 'per', 'percent', 'perfect', 'perform', 'performance', 'performed', 'performing', 'perhaps', 'period', 'perry', 'person', 'personal', 'personality', 'peter', 'phone', 'photo', 'photographed', 'physical', 'pic', 'pick', 'picture', 'piece', 'pink', 'pitt', 'place', 'plan', 'play', 'played', 'player', 'playing', 'please', 'plus', 'point', 'police', 'policy', 'political', 'pop', 'popular', 'position', 'positive', 'possible', 'post', 'posted', 'power', 'powerful', 'pregnancy', 'pregnant', 'premiere', 'premiered', 'present', 'president', 'presidential', 'press', 'pretty', 'previous', 'previously', 'price', 'prince', 'princess', 'prior', 'prison', 'private', 'probably', 'problem', 'process', 'produced', 'producer', 'product', 'production', 'professional', 'profile', 'program', 'project', 'property', 'proud', 'provide', 'public', 'publication', 'publicly', 'published', 'push', 'put', 'putting', 'queen', 'question', 'quickly', 'quite', 'race', 'rachel', 'radio', 'raise', 'raised', 'rapper', 'rather', 'rating', 'reached', 'reaction', 'read', 'reading', 'ready', 'real', 'reality', 'really', 'reason', 'received', 'recent', 'recently', 'reception', 'record', 'recorded', 'recording', 'red', 'regina', 'regular', 'related', 'relationship', 'release', 'released', 'remember', 'rep', 'report', 'reported', 'reportedly', 'reporter', 'republican', 'request', 'respect', 'responded', 'response', 'rest', 'restaurant', 'result', 'return', 'returned', 'reunion', 'revealed', 'reveals', 'review', 'right', 'rihanna', 'ring', 'road', 'rob', 'robert', 'robin', 'rock', 'role', 'romance', 'romantic', 'room', 'rose', 'round', 'royal', 'rule', 'rumor', 'run', 'running', 'russian', 'ryan', 'safe', 'said', 'sale', 'sam', 'san', 'sander', 'sarah', 'saturday', 'save', 'saw', 'say', 'saying', 'scandal', 'scene', 'school', 'scott', 'screen', 'season', 'second', 'secret', 'secretary', 'security', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'selena', 'self', 'senator', 'sense', 'sent', 'separate', 'separation', 'september', 'sequel', 'series', 'serious', 'served', 'service', 'set', 'seven', 'several', 'sex', 'sexual', 'shape', 'share', 'shared', 'sharing', 'shelton', 'shirt', 'shocking', 'shoot', 'shooting', 'short', 'shortly', 'shot', 'show', 'showed', 'showing', 'side', 'sign', 'signed', 'similar', 'simply', 'since', 'singer', 'singing', 'single', 'sister', 'site', 'sitting', 'situation', 'six', 'skin', 'small', 'smith', 'social', 'sold', 'solo', 'somebody', 'someone', 'something', 'sometimes', 'son', 'song', 'soon', 'sorry', 'sort', 'sound', 'source', 'south', 'space', 'speak', 'speaking', 'special', 'speculation', 'speech', 'spend', 'spending', 'spent', 'split', 'spoke', 'sport', 'spot', 'spotted', 'springsteen', 'st', 'stage', 'stand', 'standing', 'star', 'starred', 'starring', 'start', 'started', 'starting', 'state', 'stated', 'statement', 'stay', 'stefani', 'step', 'stephen', 'steve', 'still', 'stone', 'stop', 'store', 'story', 'straight', 'stranger', 'street', 'strong', 'struggle', 'student', 'studio', 'stuff', 'stunt', 'style', 'subject', 'success', 'successful', 'suicide', 'suit', 'summer', 'sun', 'sunday', 'super', 'support', 'supporting', 'sure', 'surgery', 'surprise', 'sweet', 'swift', 'system', 'table', 'tabloid', 'take', 'taken', 'taking', 'talent', 'talk', 'talked', 'talking', 'tape', 'tax', 'taylor', 'team', 'teen', 'television', 'tell', 'telling', 'ten', 'term', 'texas', 'thank', 'thanks', 'theater', 'theroux', 'thing', 'think', 'thinking', 'third', 'thomas', 'thompson', 'though', 'thought', 'three', 'throne', 'throughout', 'thursday', 'time', 'title', 'titled', 'tmz', 'today', 'together', 'told', 'tom', 'tonight', 'tony', 'took', 'top', 'total', 'totally', 'touch', 'tough', 'tour', 'town', 'track', 'travel', 'treatment', 'trial', 'tried', 'trip', 'true', 'truly', 'trump', 'trust', 'truth', 'try', 'trying', 'tuesday', 'turn', 'turned', 'tv', 'tweet', 'tweeted', 'twin', 'twitter', 'two', 'type', 'uk', 'ultimately', 'understand', 'union', 'united', 'university', 'upcoming', 'upon', 'urban', 'usa', 'use', 'used', 'using', 'value', 'variety', 'various', 'vega', 'version', 'via', 'victim', 'victoria', 'video', 'view', 'viewer', 'visit', 'vocal', 'voice', 'vote', 'voted', 'wait', 'wake', 'walk', 'walked', 'walking', 'wall', 'want', 'wanted', 'war', 'washington', 'watch', 'watched', 'watching', 'water', 'way', 'wear', 'wearing', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weekly', 'weeknd', 'weight', 'weinstein', 'well', 'went', 'west', 'whatever', 'whether', 'white', 'whole', 'whose', 'wife', 'william', 'williams', 'win', 'windsor', 'winner', 'winning', 'winter', 'wish', 'witherspoon', 'within', 'without', 'woman', 'wonder', 'word', 'wore', 'work', 'worked', 'worker', 'working', 'world', 'worldwide', 'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writing', 'written', 'wrong', 'wrote', 'yard', 'yeah', 'year', 'yes', 'yet', 'york', 'young', 'younger', 'youtube']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cee519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yard</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059688</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053386</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028430</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.045448</td>\n",
       "      <td>0.113763</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.073232</td>\n",
       "      <td>0.092088</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.01264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131591</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.040386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150907</td>\n",
       "      <td>0.059359</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.031150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3988 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           000   08        10       100        11        12        13  \\\n",
       "0     0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.0  0.051924  0.000000  0.029645  0.000000  0.000000   \n",
       "2     0.000000  0.0  0.028430  0.015177  0.045448  0.113763  0.019694   \n",
       "3     0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.012172  0.0  0.000000  0.000000  0.011325  0.000000  0.000000   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "3983  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3984  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3985  0.000000  0.0  0.073182  0.000000  0.000000  0.000000  0.000000   \n",
       "3986  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3987  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            14        15        16  ...     wrote     yard  yeah      year  \\\n",
       "0     0.000000  0.000000  0.000000  ...  0.059688  0.00000   0.0  0.065537   \n",
       "1     0.000000  0.000000  0.000000  ...  0.053386  0.00000   0.0  0.000000   \n",
       "2     0.073232  0.092088  0.020935  ...  0.005846  0.01264   0.0  0.131591   \n",
       "3     0.000000  0.000000  0.000000  ...  0.000000  0.00000   0.0  0.069715   \n",
       "4     0.000000  0.000000  0.000000  ...  0.000000  0.00000   0.0  0.011196   \n",
       "...        ...       ...       ...  ...       ...      ...   ...       ...   \n",
       "3983  0.000000  0.118698  0.000000  ...  0.000000  0.00000   0.0  0.115835   \n",
       "3984  0.000000  0.000000  0.000000  ...  0.000000  0.00000   0.0  0.150907   \n",
       "3985  0.000000  0.000000  0.000000  ...  0.000000  0.00000   0.0  0.082616   \n",
       "3986  0.000000  0.000000  0.000000  ...  0.000000  0.00000   0.0  0.041900   \n",
       "3987  0.000000  0.000000  0.000000  ...  0.000000  0.00000   0.0  0.029707   \n",
       "\n",
       "           yes       yet      york     young  younger   youtube  \n",
       "0     0.000000  0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "1     0.000000  0.000000  0.027347  0.000000      0.0  0.000000  \n",
       "2     0.007575  0.006509  0.023957  0.040386      0.0  0.000000  \n",
       "3     0.000000  0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "4     0.000000  0.000000  0.052234  0.000000      0.0  0.000000  \n",
       "...        ...       ...       ...       ...      ...       ...  \n",
       "3983  0.000000  0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "3984  0.059359  0.051010  0.000000  0.000000      0.0  0.000000  \n",
       "3985  0.000000  0.000000  0.000000  0.086630      0.0  0.000000  \n",
       "3986  0.000000  0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "3987  0.000000  0.000000  0.027718  0.031150      0.0  0.042354  \n",
       "\n",
       "[3988 rows x 1500 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_train.toarray(),columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff478605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Naive-Bayes classifier for building the NLP model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "nbclassifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a779d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbclassifier.fit(count_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b25c7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nbclassifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7921deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718436873747495\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97c2dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using countvectorizer the model that is built has given an accuracy of 72%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c77e60e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[459 144]\n",
      " [137 258]]\n"
     ]
    }
   ],
   "source": [
    "#Lets analyze the accuracy using confusion matrix\n",
    "cm = metrics.confusion_matrix(y_pred, y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6328c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718436873747495\n"
     ]
    }
   ],
   "source": [
    "print((459+258)/(144+137+459+258))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So out of 998 data, there are 459 and 258 predictions where the model predicted correctly whether the news is real or fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7e5fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbclassifier.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aceab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf = nbclassifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab2d1240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404809619238477\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27d7876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[514 177]\n",
      " [ 82 225]]\n"
     ]
    }
   ],
   "source": [
    "#Lets analyze the accuracy using confusion matrix\n",
    "cm = metrics.confusion_matrix(y_pred_tfidf, y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40e4c889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404809619238477\n"
     ]
    }
   ],
   "source": [
    "print((514+225)/(514+225+177+82))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e80e4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So out of 998 data, there are 514 and 225 predictions where the model predicted correctly whether the news is real or fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2330bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using tfidfvectorizer the model that is built has given an accuracy of 74%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b577d",
   "metadata": {},
   "source": [
    "### So compared to countevectorizer the tfidfvectorizer is giving the best accuracy for the built NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1ff59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
